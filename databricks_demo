# File location and type
file_location = "/FileStore/tables/yellow_tripdata_2023_01-1.parquet"
file_type = "parquet"

# CSV options
infer_schema = "true"
first_row_is_header = "false"
delimiter = ","

# The applied options are for CSV files. For other file types, these will be ignored.
df = spark.read.format(file_type) \
  .option("inferSchema", infer_schema) \
  .option("header", first_row_is_header) \
  .option("sep", delimiter) \
  .load(file_location)

# display(df)
# df.show(truncate = False)

df.createOrReplaceTempView("temp_table")

# create new columns for Day Month and Year from existing timesptamp
df=df.withColumn("day",dayofmonth("tpep_pickup_datetime"))\
.withColumn("month",month("tpep_pickup_datetime"))\
.withColumn("year",year("tpep_pickup_datetime"))

# create new column Payment_method
df=df.withColumn("payment_method",when (col("payment_type")==0,"Cash")
                  .when (col("payment_type")==1,"DebitCard")
                  .when (col("payment_type")==2,"CreditCard")
                  .when (col("payment_type")==3,"UPI")
                  .when (col("payment_type")==4,"E-Bank"))
                  
                  
  df.filter(df.day=='31').count()
  
  df_part=df.write.mode("overwrite").partitionBy("Day").option("header",True).format("parquet").save("/output/result")
  
  %fs
ls /output/result/

%fs
ls /output/result/Day=31/

# create new Column Vendor_name 
df=df.withColumn("Vendor_name",when(col("VendorID")=='1',"A")
                .when(col("VendorID")=='2',"B"))

 
