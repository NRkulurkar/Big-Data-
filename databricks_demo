# File location and type
file_location = "/FileStore/tables/yellow_tripdata_2023_01-1.parquet"
file_type = "parquet"

# CSV options
infer_schema = "true"
first_row_is_header = "false"
delimiter = ","

# The applied options are for CSV files. For other file types, these will be ignored.
df = spark.read.format(file_type) \
  .option("inferSchema", infer_schema) \
  .option("header", first_row_is_header) \
  .option("sep", delimiter) \
  .load(file_location)

# display(df)
# df.show(truncate = False)

df.createOrReplaceTempView("temp_table")

# create new columns for Day Month and Year from existing timesptamp
df=df.withColumn("day",dayofmonth("tpep_pickup_datetime"))\
.withColumn("month",month("tpep_pickup_datetime"))\
.withColumn("year",year("tpep_pickup_datetime"))

# create new column Payment_method
df=df.withColumn("payment_method",when (col("payment_type")==0,"Cash")
                  .when (col("payment_type")==1,"DebitCard")
                  .when (col("payment_type")==2,"CreditCard")
                  .when (col("payment_type")==3,"UPI")
                  .when (col("payment_type")==4,"E-Bank"))
                  
                  
  df.filter(df.day=='31').count()
  
  df_part=df.write.mode("overwrite").partitionBy("Day").option("header",True).format("parquet").save("/output/result")
  
  %fs
ls /output/result/

%fs
ls /output/result/Day=31/

# create new Column Vendor_name 
df=df.withColumn("Vendor_name",when(col("VendorID")=='1',"A")
                .when(col("VendorID")=='2',"B"))

parqDf=spark.read.option("header",True).parquet("/output/result")

parqDf.createOrReplaceTempView("taxi")

# sql query to get total number of passengers for each vendors
df_sql=spark.sql("select VendorID,sum(passenger_count) as total_passenger from taxi group by VendorID")

#sql query to get total amount for each payment method for every Vendor
df_pay=spark.sql("select Vendor_name, payment_method ,sum(total_amount) as total_amount from taxi group by Vendor_name,payment_method order by Vendor_name").show()

# sql query to get column having total amount by Cash and by online method for each Vendor
df_pay_mode=spark.sql("select Vendor_name, sum(case when payment_method='Cash' then total_amount else 0 end)as Cash_Amount,sum(case when payment_method in('DebitCard','UPI','CreditCard','E-Bank') then total_amount else 0 end)as Online_Amount from taxi group by Vendor_name").show()


# find out duration of each trip
duration_seconds=(unix_timestamp(col("tpep_dropoff_datetime"))-unix_timestamp(col("tpep_pickup_datetime")))
# add a new column to the DataFrame with the duration in minutes

duration_time=from_unixtime(duration_seconds,"HH:mm:ss")

parqDf=parqDf.withColumn("duration_time",duration_time)

parqDf=parqDf.withColumn("duration_time",col("duration_time").cast("timestamp"))


# convert pyspark df to pandas df and plot it in matplotlib

# convert pyspark df to pandas df
panda_df=df_sql.toPandas()
panda_df.plot.bar(x="VendorID",y="total_passenger",rot=90)
plt.show()


